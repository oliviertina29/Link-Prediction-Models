{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"OLIV00%%\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Récupérer les nœuds avec leur nom et type\n",
    "    nodes_query = \"MATCH (n) RETURN ID(n) AS id, n.name AS name, n.type AS type\"\n",
    "    nodes_result = session.run(nodes_query)\n",
    "\n",
    "    # Parcourir les résultats et ajouter les nœuds au graphe\n",
    "    for record in nodes_result:\n",
    "        node_id = record[\"id\"]\n",
    "        node_name = record[\"name\"]\n",
    "        node_type = record[\"type\"]\n",
    "        if node_id is not None:\n",
    "            graph.add_node(node_id, name=node_name, type=node_type)\n",
    "\n",
    "    # Récupérer les relations\n",
    "    relations_query = \"MATCH ()-[r]->() RETURN ID(startNode(r)) AS source_id, ID(endNode(r)) AS target_id\"\n",
    "    relations_result = session.run(relations_query)\n",
    "\n",
    "    # Ajouter les relations entre les nœuds\n",
    "    for record in relations_result:\n",
    "        source_node_id = record[\"source_id\"]\n",
    "        target_node_id = record[\"target_id\"]\n",
    "        if source_node_id is not None and target_node_id is not None:\n",
    "            graph.add_edge(source_node_id, target_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph to a pandas DataFrame\n",
    "df = pd.DataFrame(graph.nodes(data=True), columns=[\"node_id\", \"attributes\"])\n",
    "df[\"node_type\"] = df[\"attributes\"].apply(lambda x: x.get(\"type\"))\n",
    "df[\"node_name\"] = df[\"attributes\"].apply(lambda x: x.get(\"name\"))\n",
    "\n",
    "# Drop the unnecessary 'attributes' column\n",
    "df.drop(columns=[\"attributes\"], inplace=True)\n",
    "\n",
    "# Check if the DataFrame is empty\n",
    "if df.empty:\n",
    "    raise ValueError(\"The dataset is empty. Please check your Neo4j query and data.\")\n",
    "\n",
    "# Prepare the target variable ('link' column)\n",
    "df[\"link\"] = 1\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    # Create a graph projection for link prediction using GDS\n",
    "    session.run(\"CALL gds.graph.project('link_prediction_graph', '*', '*')\")\n",
    "    \n",
    "with driver.session() as session:\n",
    "    # Compute graph embeddings using Node2Vec algorithm\n",
    "    session.run(\"\"\"\n",
    "    CALL gds.beta.node2vec.stream('link_prediction_graph', {\n",
    "        embeddingDimension: 64,\n",
    "        iterations: 10,\n",
    "        walkLength: 20,\n",
    "        inOutFactor: 1.0,\n",
    "        returnFactor: 1.0\n",
    "    })\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the node embeddings\n",
    "node_embeddings = []\n",
    "\n",
    "# Compute graph embeddings using Node2Vec algorithm and fetch the embeddings\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        CALL gds.beta.node2vec.stream('link_prediction_graph', {\n",
    "            embeddingDimension: 64,\n",
    "            iterations: 10,\n",
    "            walkLength: 20,\n",
    "            inOutFactor: 1.0,\n",
    "            returnFactor: 1.0\n",
    "        })\n",
    "        YIELD nodeId, embedding\n",
    "        RETURN nodeId, gds.util.asNode(nodeId).name AS node_name, gds.util.asNode(nodeId).type AS node_type, embedding\n",
    "    \"\"\")\n",
    "\n",
    "    # Iterate through the result and append embeddings to the list\n",
    "    for record in result:\n",
    "        node_id = record[\"nodeId\"]\n",
    "        node_name = record[\"node_name\"]\n",
    "        node_type = record[\"node_type\"]\n",
    "        embedding = record[\"embedding\"]\n",
    "        node_embeddings.append((node_id, node_name, node_type, embedding))\n",
    "\n",
    "# Create a DataFrame to store the node embeddings\n",
    "columns = [\"node_id\", \"node_name\", \"node_type\", \"embedding\"]\n",
    "node_embeddings_df = pd.DataFrame(node_embeddings, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>node_name</th>\n",
       "      <th>node_type</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Couple unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.0015262243105098605, 0.004842257592827082, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dynamic unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.0015249720308929682, 0.00751839391887188, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Overhung unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.00121641019359231, -0.000427287450293079, -...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Structural looseness</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.0015882368898019195, 0.002190080238506198, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Angular misalignment</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.0060586994513869286, 0.0023688809014856815,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id             node_name    node_type  \\\n",
       "0        0      Couple unbalance  Explanation   \n",
       "1        1     Dynamic unbalance  Explanation   \n",
       "2        2    Overhung unbalance  Explanation   \n",
       "3        3  Structural looseness  Explanation   \n",
       "4        4  Angular misalignment  Explanation   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0015262243105098605, 0.004842257592827082, ...  \n",
       "1  [0.0015249720308929682, 0.00751839391887188, -...  \n",
       "2  [0.00121641019359231, -0.000427287450293079, -...  \n",
       "3  [0.0015882368898019195, 0.002190080238506198, ...  \n",
       "4  [0.0060586994513869286, 0.0023688809014856815,...  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suppose 'node_embeddings' is a dictionary mapping node IDs to their embeddings\n",
    "# 'positive_edges' is a list of existing edges, 'negative_edges' is a list of non-existing edges\n",
    "\n",
    "# Step 1: Generate labels for positive and negative edges\n",
    "pos_labels = np.ones(len(positive_edges))\n",
    "neg_labels = np.zeros(len(negative_edges))\n",
    "\n",
    "# Combine labels and edges\n",
    "edges = np.vstack((positive_edges, negative_edges))\n",
    "labels = np.concatenate((pos_labels, neg_labels))\n",
    "\n",
    "# Step 2: Generate feature vectors for candidate links\n",
    "candidate_features = np.array([np.concatenate((node_embeddings[u], node_embeddings[v])) for u, v in edges])\n",
    "\n",
    "# Step 3: Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(candidate_features, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Step 4: Train a classifier\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Step 5: Predict links\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Step 6: Evaluate the model\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "print(\"Accuracy:\", accuracy)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
