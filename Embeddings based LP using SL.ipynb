{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connecting to the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"OLIV00%%\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generating graph embeddings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>node_name</th>\n",
       "      <th>node_type</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Couple unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.0002608242502901703, -0.0016390503151342273...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dynamic unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.00020098022650927305, 0.002685168059542775,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Overhung unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.00021156920411158353, 0.005176438018679619,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Structural looseness</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.0002050298935500905, -0.0027629134710878134...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Angular misalignment</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.00021222594659775496, -0.000109208696812856...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id             node_name    node_type  \\\n",
       "0        0      Couple unbalance  Explanation   \n",
       "1        1     Dynamic unbalance  Explanation   \n",
       "2        2    Overhung unbalance  Explanation   \n",
       "3        3  Structural looseness  Explanation   \n",
       "4        4  Angular misalignment  Explanation   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.0002608242502901703, -0.0016390503151342273...  \n",
       "1  [0.00020098022650927305, 0.002685168059542775,...  \n",
       "2  [0.00021156920411158353, 0.005176438018679619,...  \n",
       "3  [0.0002050298935500905, -0.0027629134710878134...  \n",
       "4  [0.00021222594659775496, -0.000109208696812856...  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "with driver.session() as session:\n",
    "    nodes_query = \"MATCH (n) RETURN ID(n) AS id, n.name AS name, n.type AS type\"\n",
    "    nodes_result = session.run(nodes_query)\n",
    "\n",
    "    for record in nodes_result:\n",
    "        node_id = record[\"id\"]\n",
    "        node_name = record[\"name\"]\n",
    "        node_type = record[\"type\"]\n",
    "        if node_id is not None:\n",
    "            graph.add_node(node_id, name=node_name, type=node_type)\n",
    "\n",
    "    relations_query = \"MATCH ()-[r]->() RETURN ID(startNode(r)) AS source_id, ID(endNode(r)) AS target_id\"\n",
    "    relations_result = session.run(relations_query)\n",
    "\n",
    "    for record in relations_result:\n",
    "        source_node_id = record[\"source_id\"]\n",
    "        target_node_id = record[\"target_id\"]\n",
    "        if source_node_id is not None and target_node_id is not None:\n",
    "            graph.add_edge(source_node_id, target_node_id)\n",
    "            \n",
    "            \n",
    "df = pd.DataFrame(graph.nodes(data=True), columns=[\"node_id\", \"attributes\"])\n",
    "df[\"node_type\"] = df[\"attributes\"].apply(lambda x: x.get(\"type\"))\n",
    "df[\"node_name\"] = df[\"attributes\"].apply(lambda x: x.get(\"name\"))\n",
    "\n",
    "df.drop(columns=[\"attributes\"], inplace=True)\n",
    "\n",
    "if df.empty:\n",
    "    raise ValueError(\"The dataset is empty. Please check your Neo4j query and data.\")\n",
    "    \n",
    "    \n",
    "    \n",
    "# Embeddings ##########################################################################\n",
    "node_embeddings = []\n",
    "\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        CALL gds.beta.node2vec.stream('link_prediction_graph', {\n",
    "            embeddingDimension: 64,\n",
    "            iterations: 10,\n",
    "            walkLength: 20,\n",
    "            inOutFactor: 1.0,\n",
    "            returnFactor: 1.0\n",
    "        })\n",
    "        YIELD nodeId, embedding\n",
    "        RETURN nodeId, gds.util.asNode(nodeId).name AS node_name, gds.util.asNode(nodeId).type AS node_type, embedding\n",
    "    \"\"\")\n",
    "\n",
    "    for record in result:\n",
    "        node_id = record[\"nodeId\"]\n",
    "        node_name = record[\"node_name\"]\n",
    "        node_type = record[\"node_type\"]\n",
    "        embedding = record[\"embedding\"]\n",
    "        node_embeddings.append((node_id, node_name, node_type, embedding))\n",
    "\n",
    "columns = [\"node_id\", \"node_name\", \"node_type\", \"embedding\"]\n",
    "node_embeddings_df = pd.DataFrame(node_embeddings, columns=columns)\n",
    "node_embeddings_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch the graph embeddings and create the ML dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n",
      "\n",
      "Positive edges: (17, 2)\n",
      "Negative edges: (559, 2)\n",
      "\n",
      "Edges: (576, 2)\n",
      "Labels: (576, 1)\n"
     ]
    }
   ],
   "source": [
    "def fetch_graph_data():\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (n1)-[r]->(n2) RETURN id(n1) AS start, id(n2) AS end, type(r) AS relationship\"\n",
    "        )\n",
    "        data = [(record[\"start\"], record[\"end\"], record[\"relationship\"]) for record in result]\n",
    "    return data\n",
    "graph_data = fetch_graph_data()\n",
    "\n",
    "\n",
    "G = nx.DiGraph()\n",
    "for start, end, relationship in graph_data:\n",
    "    G.add_node(start)\n",
    "    G.add_node(end)\n",
    "    G.add_edge(start, end, relationship=relationship)\n",
    "\n",
    "adj_matrix = nx.to_numpy_matrix(G, dtype=int)\n",
    "node_order = sorted(G.nodes())\n",
    "node_index_map = {node_id: index for index, node_id in enumerate(node_order)}\n",
    "adj_matrix_reordered = np.array([[adj_matrix[node_index_map[start], node_index_map[end]] for end in node_order] for start in node_order])\n",
    "print(adj_matrix_reordered)\n",
    "\n",
    "\n",
    "\n",
    "# Node features and labels ############################################################################\n",
    "def generate_positive_examples(adj_matrix):\n",
    "    pos_edges = np.array(np.where(adj_matrix == 1)).T\n",
    "    return pos_edges\n",
    "\n",
    "def generate_negative_examples(adj_matrix):\n",
    "    neg_edges = np.array(np.where(adj_matrix == 0)).T\n",
    "    return neg_edges\n",
    "\n",
    "pos_edges = generate_positive_examples(adj_matrix_reordered)\n",
    "neg_edges = generate_negative_examples(adj_matrix_reordered)\n",
    "\n",
    "print(\"\\nPositive edges: {}\".format(pos_edges.shape))\n",
    "print(\"Negative edges: {}\".format(neg_edges.shape))\n",
    "\n",
    "pos_labels = np.ones(pos_edges.shape[0])\n",
    "neg_labels = np.zeros(neg_edges.shape[0])\n",
    "\n",
    "edges = np.vstack((pos_edges, neg_edges))\n",
    "labels = np.concatenate((pos_labels, neg_labels))\n",
    "\n",
    "labels = labels.reshape(576, 1)\n",
    "\n",
    "print(\"\\nEdges: {}\".format(edges.shape))\n",
    "print(\"Labels: {}\".format(labels.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9568965517241379\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.96      1.00      0.98       111\n",
      "         1.0       0.00      0.00      0.00         5\n",
      "\n",
      "    accuracy                           0.96       116\n",
      "   macro avg       0.48      0.50      0.49       116\n",
      "weighted avg       0.92      0.96      0.94       116\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olivi\\anaconda3\\envs\\Py_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\olivi\\anaconda3\\envs\\Py_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "C:\\Users\\olivi\\anaconda3\\envs\\Py_env\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Combine positive and negative examples and labels\n",
    "edges = np.vstack((pos_edges, neg_edges))\n",
    "labels = np.concatenate((pos_labels, neg_labels))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_edges, X_test_edges, y_train, y_test = train_test_split(edges, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract embeddings for the edges in the training and testing sets\n",
    "X_train_embeddings = np.array([node_embeddings_df.loc[node_id][\"embedding\"] for edge in X_train_edges])\n",
    "X_test_embeddings = np.array([node_embeddings_df.loc[node_id][\"embedding\"] for edge in X_test_edges])\n",
    "\n",
    "# Train a logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Predict link existence for the testing set\n",
    "y_pred = logreg_model.predict(X_test_embeddings)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(920, 64)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_embeddings.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(460,)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "# Combine positive and negative examples and labels\n",
    "edges = np.vstack((pos_edges, neg_edges))\n",
    "labels = np.concatenate((pos_labels, neg_labels))\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train_edges, X_test_edges, y_train, y_test = train_test_split(edges, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Extract embeddings for the edges in the training and testing sets\n",
    "X_train_embeddings = np.array([node_embeddings_df.loc[node_id][\"embedding\"] for edge in X_train_edges for node_id in edge])\n",
    "X_test_embeddings = np.array([node_embeddings_df.loc[node_id][\"embedding\"] for edge in X_test_edges for node_id in edge])\n",
    "\n",
    "# Train a logistic regression model\n",
    "logreg_model = LogisticRegression()\n",
    "logreg_model.fit(X_train_embeddings, y_train)\n",
    "\n",
    "# Predict link existence for the testing set\n",
    "y_pred = logreg_model.predict(X_test_embeddings)\n",
    "\n",
    "# Evaluate the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "classification_rep = classification_report(y_test, y_pred)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Classification Report:\\n\", classification_rep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    session.run(\"CALL gds.graph.project('link_prediction_graph', '*', '*')\")\n",
    "    \n",
    "with driver.session() as session:\n",
    "    session.run(\"\"\"\n",
    "    CALL gds.beta.node2vec.stream('link_prediction_graph', {\n",
    "        embeddingDimension: 64,\n",
    "        iterations: 10,\n",
    "        walkLength: 20,\n",
    "        inOutFactor: 1.0,\n",
    "        returnFactor: 1.0\n",
    "    })\n",
    "    \"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
