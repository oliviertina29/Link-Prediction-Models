{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5ae9fc",
   "metadata": {},
   "source": [
    "## Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fe7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install node2vec\n",
    "#!pip install neo4j\n",
    "#!pip install --upgrade networkx\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76668d75",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2cdb896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olivi\\anaconda3\\envs\\Py_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
    "from neo4j import GraphDatabase\n",
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.keras.layers import BatchNormalization, Dropout, ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db0339",
   "metadata": {},
   "source": [
    "## Connecting to the neo4j database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a4b88be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"OLIV00%%\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff062521",
   "metadata": {},
   "source": [
    "## Loading of the KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be9f6e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 0\n",
      "Node Name: Iv1\n",
      "Node Type: fftvInterval\n",
      "\n",
      "Node ID: 1\n",
      "Node Name: Iv2\n",
      "Node Type: fftvInterval\n",
      "\n",
      "Node ID: 2\n",
      "Node Name: Iv3\n",
      "Node Type: fftvInterval\n",
      "\n",
      "Node ID: 3\n",
      "Node Name: Iv4\n",
      "Node Type: fftvInterval\n",
      "\n",
      "Node ID: 4\n",
      "Node Name: Iv5\n",
      "Node Type: fftvInterval\n",
      "\n",
      "Node ID: 5\n",
      "Node Name: Iv6\n",
      "Node Type: fftvInterval\n",
      "\n",
      "Node ID: 6\n",
      "Node Name: Iv7\n",
      "Node Type: fftvInterval\n",
      "\n",
      "Node ID: 7\n",
      "Node Name: Ig1\n",
      "Node Type: fftgInterval\n",
      "\n",
      "Node ID: 8\n",
      "Node Name: Ig2\n",
      "Node Type: fftgInterval\n",
      "\n",
      "Node ID: 9\n",
      "Node Name: Ig3\n",
      "Node Type: fftgInterval\n",
      "\n",
      "Node ID: 10\n",
      "Node Name: Ig4\n",
      "Node Type: fftgInterval\n",
      "\n",
      "Node ID: 11\n",
      "Node Name: Ig5\n",
      "Node Type: fftgInterval\n",
      "\n",
      "Node ID: 12\n",
      "Node Name: Ig6\n",
      "Node Type: fftgInterval\n",
      "\n",
      "Node ID: 13\n",
      "Node Name: Ig7\n",
      "Node Type: fftgInterval\n",
      "\n",
      "Node ID: 14\n",
      "Node Name: Static unbalance\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 15\n",
      "Node Name: Couple unbalance\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 16\n",
      "Node Name: Dynamic unbalance\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 17\n",
      "Node Name: Overhung unbalance\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 18\n",
      "Node Name: Structural looseness\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 19\n",
      "Node Name: Angular misalignment\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 20\n",
      "Node Name: General misalignment\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 21\n",
      "Node Name: Parallel misalignment\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 22\n",
      "Node Name: Mechanical loosenes\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 23\n",
      "Node Name: Component loosenes\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 24\n",
      "Node Name: Bearing Lubrication Fault\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 25\n",
      "Node Name: Excessive gear\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 26\n",
      "Node Name: Excessive loading\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 27\n",
      "Node Name: Mechanical misalignment\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 28\n",
      "Node Name: Pump\n",
      "Node Type: Component\n",
      "\n",
      "Node ID: 29\n",
      "Node Name: Fan\n",
      "Node Type: Component\n",
      "\n",
      "Node ID: 30\n",
      "Node Name: Engine\n",
      "Node Type: Component\n",
      "\n",
      "Node ID: 31\n",
      "Node Name: fftv\n",
      "Node Type: measure_unit\n",
      "\n",
      "Node ID: 32\n",
      "Node Name: fftg\n",
      "Node Type: measure_unit\n",
      "\n",
      "Node ID: 33\n",
      "Node Name: Normal\n",
      "Node Type: Normal\n",
      "\n",
      "Node ID: 34\n",
      "Node Name: Imbalance\n",
      "Node Type: Imbalance\n",
      "\n",
      "Node ID: 35\n",
      "Node Name: Structural fault\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 36\n",
      "Node Name: Misalignment\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 37\n",
      "Node Name: looseness\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 38\n",
      "Node Name: Bearing Fault\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 39\n",
      "Node Name: Gear Fault\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 40\n",
      "Node Name: P1\n",
      "Node Type: Sensor\n",
      "\n",
      "Node ID: 41\n",
      "Node Name: P2\n",
      "Node Type: Sensor\n",
      "\n",
      "Node ID: 42\n",
      "Node Name: P3\n",
      "Node Type: Sensor\n",
      "\n",
      "Node ID: 43\n",
      "Node Name: P4\n",
      "Node Type: Sensor\n",
      "\n",
      "Node ID: 44\n",
      "Node Name: Machine_OCP\n",
      "Node Type: Engine_pump\n",
      "\n",
      "Node ID: 45\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 46\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 47\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 48\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 49\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 50\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 51\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 52\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 53\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 54\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 55\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 56\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 57\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n",
      "Node ID: 58\n",
      "Node Name: And\n",
      "Node Type: Operation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Récupérer les nœuds avec leur nom et type\n",
    "    nodes_query = \"MATCH (n) RETURN ID(n) AS id, n.name AS name, n.type AS type\"\n",
    "    nodes_result = session.run(nodes_query)\n",
    "\n",
    "    # Parcourir les résultats et ajouter les nœuds au graphe\n",
    "    for record in nodes_result:\n",
    "        node_id = record[\"id\"]\n",
    "        node_name = record[\"name\"]\n",
    "        node_type = record[\"type\"]\n",
    "        if node_id is not None:\n",
    "            graph.add_node(node_id, name=node_name, type=node_type)\n",
    "\n",
    "    # Récupérer les relations\n",
    "    relations_query = \"MATCH ()-[r]->() RETURN ID(startNode(r)) AS source_id, ID(endNode(r)) AS target_id\"\n",
    "    relations_result = session.run(relations_query)\n",
    "\n",
    "    # Ajouter les relations entre les nœuds\n",
    "    for record in relations_result:\n",
    "        source_node_id = record[\"source_id\"]\n",
    "        target_node_id = record[\"target_id\"]\n",
    "        if source_node_id is not None and target_node_id is not None:\n",
    "            graph.add_edge(source_node_id, target_node_id)\n",
    "\n",
    "# Afficher les informations des nœuds\n",
    "for node_id, node_data in graph.nodes(data=True):\n",
    "    print(\"Node ID:\", node_id)\n",
    "    print(\"Node Name:\", node_data.get(\"name\"))\n",
    "    print(\"Node Type:\", node_data.get(\"type\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9cda3",
   "metadata": {},
   "source": [
    "## Features extraction from nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b3f02caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'name': 'Iv1', 'type': 'fftvInterval'}\n"
     ]
    }
   ],
   "source": [
    "# Préparer les caractéristiques des nœuds\n",
    "node_features = []\n",
    "\n",
    "# Récupérer les attributs \"id\", \"name\" et \"type\" des nœuds dans le graphe\n",
    "for node_id in graph.nodes:\n",
    "    node_data = graph.nodes[node_id]\n",
    "    node_feature = {\n",
    "        \"id\": node_id,\n",
    "        \"name\": node_data[\"name\"],\n",
    "        \"type\": node_data[\"type\"]\n",
    "    }\n",
    "    node_features.append(node_feature)\n",
    "\n",
    "# Convertir les caractéristiques des nœuds en un tableau numpy\n",
    "#X = np.array([(node[\"id\"], node[\"name\"], node[\"type\"]) for node in node_features])\n",
    "X = np.array(node_features)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2778eeaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Computing transition probabilities: 100%|████████████████████████████████████████████| 59/59 [00:00<00:00, 4417.42it/s]\n"
     ]
    },
    {
     "ename": "TerminatedWorkerError",
     "evalue": "A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m                     Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_6340\\3539243407.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Exécutez l'algorithme Node2Vec\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mnode2vec\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mNode2Vec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgraph\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdimensions\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwalk_length\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_walks\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m60\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m4\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Entraînez le modèle pour apprendre les embeddings\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnode2vec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwindow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmin_count\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\node2vec\\node2vec.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, graph, dimensions, walk_length, num_walks, p, q, weight_key, workers, sampling_strategy, quiet, temp_folder, seed)\u001b[0m\n\u001b[0;32m     72\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     73\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_precompute_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 74\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwalks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_generate_walks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     76\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_precompute_probabilities\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\node2vec\\node2vec.py\u001b[0m in \u001b[0;36m_generate_walks\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    159\u001b[0m                                              self.quiet) for\n\u001b[0;32m    160\u001b[0m             \u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnum_walks\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 161\u001b[1;33m             in enumerate(num_walks_lists, 1))\n\u001b[0m\u001b[0;32m    162\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m         \u001b[0mwalks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwalk_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1942\u001b[0m         \u001b[0mnext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1943\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1944\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0moutput\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreturn_generator\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1945\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1946\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_get_outputs\u001b[1;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[0;32m   1585\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1586\u001b[0m             \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mretrieval_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1587\u001b[1;33m                 \u001b[1;32myield\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_retrieve\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1588\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1589\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mGeneratorExit\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_retrieve\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1689\u001b[0m             \u001b[1;31m# worker traceback.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1690\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_aborting\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1691\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_raise_error_fast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1692\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1693\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_raise_error_fast\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1724\u001b[0m         \u001b[1;31m# called directly or if the generator is gc'ed.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1725\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0merror_job\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1726\u001b[1;33m             \u001b[0merror_job\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_result\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1727\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1728\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_warn_exit_early\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mget_result\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    733\u001b[0m             \u001b[1;31m# callback thread, and is stored internally. It's just waiting to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    734\u001b[0m             \u001b[1;31m# be returned.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 735\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_return_or_raise\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    736\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    737\u001b[0m         \u001b[1;31m# For other backends, the main thread needs to run the retrieval step.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_return_or_raise\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    751\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    752\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mTASK_ERROR\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 753\u001b[1;33m                 \u001b[1;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    754\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    755\u001b[0m         \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mTerminatedWorkerError\u001b[0m: A worker process managed by the executor was unexpectedly terminated. This could be caused by a segmentation fault while calling the function or by an excessive memory usage causing the Operating System to kill the worker.\n"
     ]
    }
   ],
   "source": [
    "# Exécutez l'algorithme Node2Vec\n",
    "node2vec = Node2Vec(graph, dimensions=16, walk_length=15, num_walks=60, workers=4)\n",
    "\n",
    "# Entraînez le modèle pour apprendre les embeddings\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "# Obtenez les embeddings pour tous les nœuds du graphe\n",
    "embeddings = [model.wv[str(node_id)] for node_id in graph.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8e1dd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_array_to_matrix(array):\n",
    "    \"\"\"Transforms an array of arrays into a matrix.\"\"\"\n",
    "    matrix = np.array(array)\n",
    "    matrix = matrix.reshape(matrix.shape[0], -1)\n",
    "    return matrix\n",
    "\n",
    "X = transform_array_to_matrix(embeddings)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c3fb1",
   "metadata": {},
   "source": [
    "## Attention-based Compressed Relational Graph Convolutional Network (ACRGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bef700ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACRGCN(G, X, L, Decoder_layer):\n",
    "    '''\n",
    "    G : Knowledge graph\n",
    "    X : nodes features (embeddings of the nodes)\n",
    "    L : Encoder layer number\n",
    "    Decoder_layer : Decoder layer number\n",
    "    '''\n",
    "    H = X\n",
    "    for i in range(L):   \n",
    "        H = RGCN(H, G)\n",
    "        H = BN(H)\n",
    "        H = ReLU(H)\n",
    "        if i < L-1:\n",
    "            H = Dropout(H)\n",
    "    H_maxlayer = GAT(H, G)\n",
    "    \n",
    "    for i in range(Decoder_layer, 0, -1):\n",
    "        H = DeRGCN(H_maxlayer, G)\n",
    "        H = BN(H)\n",
    "        H = ReLU(H)\n",
    "        if i > 1:\n",
    "            H = Dropout(H)\n",
    "        H = np.concatenate((H, H_maxlayer), axis=1)\n",
    "    \n",
    "    E_candidate = ScoreDistMult(H)\n",
    "    \n",
    "    return E_candidate\n",
    "\n",
    "\n",
    "def RGCN(H, G):\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    for layer in range(L):\n",
    "        W_layer = np.random.normal(0, 0.01, (H.shape[1], H.shape[1]))\n",
    "        H = H@W_layer\n",
    "        H = A.dot(H)\n",
    "        H = np.maximum(H, 0)\n",
    "    return H\n",
    "\n",
    "\n",
    "def BN(H):\n",
    "    # Batch Normalization operation\n",
    "    scaler = StandardScaler()\n",
    "    H = scaler.fit_transform(H)\n",
    "    return H\n",
    "\n",
    "\n",
    "def ReLU(H):\n",
    "    # ReLU activation function\n",
    "    return np.maximum(H, 0)\n",
    "\n",
    "\n",
    "def Dropout(H, p=0.5):\n",
    "    # Dropout operation\n",
    "    mask = np.random.binomial(1, p, size=H.shape)\n",
    "    H = H * mask / p\n",
    "    return H\n",
    "\n",
    "\n",
    "def GAT(H, G, lambda_val=0.2):\n",
    "    num_nodes, feature_dim = H.shape\n",
    "    H = torch.tensor(H, dtype=torch.float32)\n",
    "    \n",
    "    # Initialize attention weight matrix (W_a) with random values\n",
    "    W_a = torch.randn(feature_dim, feature_dim, dtype=torch.float32)\n",
    "    \n",
    "    # Convert lambda_val to a PyTorch tensor with an extra dimension\n",
    "    lambda_val = torch.tensor([lambda_val], dtype=torch.float32)\n",
    "    H_a = torch.zeros_like(H)\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        neighbors = G[i]  # Get the neighbors of the ith node\n",
    "        num_neighbors = len(neighbors)\n",
    "        alpha = torch.zeros(num_neighbors)\n",
    "        \n",
    "        for j, neighbor_idx in enumerate(neighbors):\n",
    "            concat_features = torch.cat((torch.matmul(W_a, H[i]), torch.matmul(W_a, H[neighbor_idx])))\n",
    "            # Ensure lambda_val has the same shape as concat_features for element-wise operations\n",
    "            expanded_lambda_val = lambda_val.expand_as(concat_features)\n",
    "            alpha[j] = torch.exp(F.leaky_relu(torch.matmul(expanded_lambda_val, concat_features)))\n",
    "            \n",
    "        alpha = F.softmax(alpha, dim=0)\n",
    "        \n",
    "        for j, neighbor_idx in enumerate(neighbors):\n",
    "            H_a[i] += alpha[j] * torch.matmul(W_a, H[neighbor_idx])\n",
    "            \n",
    "    H_a = torch.sigmoid(H_a)\n",
    "    return H_a\n",
    "\n",
    "\n",
    "def DeRGCN(H, G):\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    W_layer = np.random.normal(0, 0.01, (H.shape[1], H.shape[1]))\n",
    "    H = H@W_layer\n",
    "    H = A.T.dot(H)\n",
    "    H = np.maximum(H, 0)\n",
    "    return H\n",
    "\n",
    "\n",
    "def ScoreDistMult(H):\n",
    "    # Score calculation using DistMult\n",
    "    scores = np.dot(H, np.transpose(H))\n",
    "    return scores\n",
    "\n",
    "\n",
    "def Sort(scores):\n",
    "    # Sort the scores in descending order\n",
    "    sorted_indices = np.argsort(scores)[::-1] \n",
    "    sorted_scores = scores[sorted_indices]\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d77ac1",
   "metadata": {},
   "source": [
    "## Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "649bfc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Appliquer l'algorithme ACRGCN\n",
    "L = 3  # Encoder layer number\n",
    "Decoder_layer = 2  # Decoder layer number\n",
    "E_candidates = ACRGCN(graph, X, L, Decoder_layer)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(E_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47041208",
   "metadata": {},
   "outputs": [],
   "source": [
    "E_candidates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e25998",
   "metadata": {},
   "source": [
    "## Close session and driver at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459b2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215dcf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0] * 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
