{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "84843a6a",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "be889dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08458b5d",
   "metadata": {},
   "source": [
    "## Connecting to the neo4j database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "37c9e658",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"OLIV00%%\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c7c2626",
   "metadata": {},
   "source": [
    "## Retrieving the graph data from Neo4j and dataset preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed5181d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Récupérer les nœuds avec leur nom et type\n",
    "    nodes_query = \"MATCH (n) RETURN ID(n) AS id, n.name AS name, n.type AS type\"\n",
    "    nodes_result = session.run(nodes_query)\n",
    "\n",
    "    # Parcourir les résultats et ajouter les nœuds au graphe\n",
    "    for record in nodes_result:\n",
    "        node_id = record[\"id\"]\n",
    "        node_name = record[\"name\"]\n",
    "        node_type = record[\"type\"]\n",
    "        if node_id is not None:\n",
    "            graph.add_node(node_id, name=node_name, type=node_type)\n",
    "\n",
    "    # Récupérer les relations\n",
    "    relations_query = \"MATCH ()-[r]->() RETURN ID(startNode(r)) AS source_id, ID(endNode(r)) AS target_id\"\n",
    "    relations_result = session.run(relations_query)\n",
    "\n",
    "    # Ajouter les relations entre les nœuds\n",
    "    for record in relations_result:\n",
    "        source_node_id = record[\"source_id\"]\n",
    "        target_node_id = record[\"target_id\"]\n",
    "        if source_node_id is not None and target_node_id is not None:\n",
    "            graph.add_edge(source_node_id, target_node_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "26eab0a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the graph to a pandas DataFrame\n",
    "df = pd.DataFrame(graph.nodes(data=True), columns=[\"node_id\", \"attributes\"])\n",
    "df[\"node_type\"] = df[\"attributes\"].apply(lambda x: x.get(\"type\"))\n",
    "df[\"node_name\"] = df[\"attributes\"].apply(lambda x: x.get(\"name\"))\n",
    "\n",
    "# Drop the unnecessary 'attributes' column\n",
    "df.drop(columns=[\"attributes\"], inplace=True)\n",
    "\n",
    "# Check if the DataFrame is empty\n",
    "if df.empty:\n",
    "    raise ValueError(\"The dataset is empty. Please check your Neo4j query and data.\")\n",
    "\n",
    "# Prepare the target variable ('link' column)\n",
    "df[\"link\"] = 1\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a47df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>node_type</th>\n",
       "      <th>node_name</th>\n",
       "      <th>link</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>Couple unbalance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>Dynamic unbalance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>Overhung unbalance</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>Structural looseness</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>Angular misalignment</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id    node_type             node_name  link\n",
       "0        0  Explanation      Couple unbalance     1\n",
       "1        1  Explanation     Dynamic unbalance     1\n",
       "2        2  Explanation    Overhung unbalance     1\n",
       "3        3  Explanation  Structural looseness     1\n",
       "4        4  Explanation  Angular misalignment     1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e1aea0e",
   "metadata": {},
   "source": [
    "## Generating graph embeddings using Neo4j's GDS library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e0457963",
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    # Create a graph projection for link prediction using GDS\n",
    "    session.run(\"CALL gds.graph.project('link_prediction_graph', '*', '*')\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9bdf8710",
   "metadata": {},
   "outputs": [],
   "source": [
    "with driver.session() as session:\n",
    "    # Compute graph embeddings using Node2Vec algorithm\n",
    "    session.run(\"\"\"\n",
    "    CALL gds.beta.node2vec.stream('link_prediction_graph', {\n",
    "        embeddingDimension: 64,\n",
    "        iterations: 10,\n",
    "        walkLength: 20,\n",
    "        inOutFactor: 1.0,\n",
    "        returnFactor: 1.0\n",
    "    })\n",
    "    \"\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7313dbdf",
   "metadata": {},
   "source": [
    "## Fetch the graph embeddings and create the machine learning dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2b7c6a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an empty list to store the node embeddings\n",
    "node_embeddings = []\n",
    "\n",
    "# Compute graph embeddings using Node2Vec algorithm and fetch the embeddings\n",
    "with driver.session() as session:\n",
    "    result = session.run(\"\"\"\n",
    "        CALL gds.beta.node2vec.stream('link_prediction_graph', {\n",
    "            embeddingDimension: 64,\n",
    "            iterations: 10,\n",
    "            walkLength: 20,\n",
    "            inOutFactor: 1.0,\n",
    "            returnFactor: 1.0\n",
    "        })\n",
    "        YIELD nodeId, embedding\n",
    "        RETURN nodeId, gds.util.asNode(nodeId).name AS node_name, gds.util.asNode(nodeId).type AS node_type, embedding\n",
    "    \"\"\")\n",
    "\n",
    "    # Iterate through the result and append embeddings to the list\n",
    "    for record in result:\n",
    "        node_id = record[\"nodeId\"]\n",
    "        node_name = record[\"node_name\"]\n",
    "        node_type = record[\"node_type\"]\n",
    "        embedding = record[\"embedding\"]\n",
    "        node_embeddings.append((node_id, node_name, node_type, embedding))\n",
    "\n",
    "# Create a DataFrame to store the node embeddings\n",
    "columns = [\"node_id\", \"node_name\", \"node_type\", \"embedding\"]\n",
    "node_embeddings_df = pd.DataFrame(node_embeddings, columns=columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c875597a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>node_id</th>\n",
       "      <th>node_name</th>\n",
       "      <th>node_type</th>\n",
       "      <th>embedding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Couple unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.007438237778842449, -0.005690622143447399, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Dynamic unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.007427668664604425, -0.002915834542363882, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>Overhung unbalance</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.00774760264903307, 0.00453847274184227, 0.0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>Structural looseness</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.007449103053659201, 0.007329504005610943, 0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Angular misalignment</td>\n",
       "      <td>Explanation</td>\n",
       "      <td>[0.007547266781330109, -0.0016168525908142328,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   node_id             node_name    node_type  \\\n",
       "0        0      Couple unbalance  Explanation   \n",
       "1        1     Dynamic unbalance  Explanation   \n",
       "2        2    Overhung unbalance  Explanation   \n",
       "3        3  Structural looseness  Explanation   \n",
       "4        4  Angular misalignment  Explanation   \n",
       "\n",
       "                                           embedding  \n",
       "0  [0.007438237778842449, -0.005690622143447399, ...  \n",
       "1  [0.007427668664604425, -0.002915834542363882, ...  \n",
       "2  [0.00774760264903307, 0.00453847274184227, 0.0...  \n",
       "3  [0.007449103053659201, 0.007329504005610943, 0...  \n",
       "4  [0.007547266781330109, -0.0016168525908142328,...  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a15f1b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names in train_df: Index(['node_id', 'node_type', 'node_name', 'link'], dtype='object')\n",
      "Column names in node_embeddings_df: Index(['node_id', 'node_name', 'node_type', 'embedding'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(\"Column names in train_df:\", train_df.columns)\n",
    "print(\"Column names in node_embeddings_df:\", node_embeddings_df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e43fb337",
   "metadata": {},
   "source": [
    "## Training a machine learning model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ccc0d7ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def link_prediction_classifier(max_iter=2000):\n",
    "    lr_clf = LogisticRegressionCV(Cs=10, cv=10, scoring=\"roc_auc\", max_iter=max_iter)\n",
    "    return Pipeline(steps=[(\"sc\", StandardScaler()), (\"clf\", lr_clf)])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "846e4779",
   "metadata": {},
   "source": [
    "## Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "298df691",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "fit() missing 1 required positional argument: 'X'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11404\\2270042281.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlink_prediction_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m2000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: fit() missing 1 required positional argument: 'X'"
     ]
    }
   ],
   "source": [
    "model = link_prediction_classifier(max_iter=2000)\n",
    "model.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "6325f47e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Imbalance</th>\n",
       "      <th>Structural fault</th>\n",
       "      <th>Misalignment</th>\n",
       "      <th>looseness</th>\n",
       "      <th>Bearing Fault</th>\n",
       "      <th>Gear Fault</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Pump</th>\n",
       "      <td>0.038418</td>\n",
       "      <td>-0.008609</td>\n",
       "      <td>-0.148771</td>\n",
       "      <td>0.080452</td>\n",
       "      <td>-0.076055</td>\n",
       "      <td>-0.007430</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fan</th>\n",
       "      <td>0.212369</td>\n",
       "      <td>-0.147346</td>\n",
       "      <td>0.155298</td>\n",
       "      <td>-0.112698</td>\n",
       "      <td>-0.039756</td>\n",
       "      <td>-0.118019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Engine</th>\n",
       "      <td>0.390948</td>\n",
       "      <td>0.184992</td>\n",
       "      <td>-0.168545</td>\n",
       "      <td>-0.168042</td>\n",
       "      <td>-0.218257</td>\n",
       "      <td>-0.117252</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Imbalance  Structural fault  Misalignment  looseness  Bearing Fault  \\\n",
       "Pump     0.038418         -0.008609     -0.148771   0.080452      -0.076055   \n",
       "Fan      0.212369         -0.147346      0.155298  -0.112698      -0.039756   \n",
       "Engine   0.390948          0.184992     -0.168545  -0.168042      -0.218257   \n",
       "\n",
       "        Gear Fault  \n",
       "Pump     -0.007430  \n",
       "Fan      -0.118019  \n",
       "Engine   -0.117252  "
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Separate the nodes of type \"component\" and nodes of types \"failure\" and \"ambalance\"\n",
    "component_nodes = node_embeddings_df[node_embeddings_df[\"node_type\"] == \"Component\"]\n",
    "failure_ambalance_nodes = node_embeddings_df[node_embeddings_df[\"node_type\"].isin([\"Failure\", \"Imbalance\"])]\n",
    "\n",
    "# Extract embeddings for each set of nodes\n",
    "component_embeddings = component_nodes[\"embedding\"].tolist()\n",
    "failure_ambalance_embeddings = failure_ambalance_nodes[\"embedding\"].tolist()\n",
    "\n",
    "# Check if embeddings are not empty\n",
    "if not component_embeddings or not failure_ambalance_embeddings:\n",
    "    print(\"Some embeddings are empty. Check if the Node2Vec computation was successful and if nodes of required types exist.\")\n",
    "else:\n",
    "    # Compute the similarity between the embeddings using cosine similarity\n",
    "    similarity_matrix = cosine_similarity(component_embeddings, failure_ambalance_embeddings)\n",
    "\n",
    "    # Create a DataFrame to store the similarity scores with node names as index and columns\n",
    "    similarity_df = pd.DataFrame(similarity_matrix, columns=failure_ambalance_nodes[\"node_name\"].tolist(), index=component_nodes[\"node_name\"].tolist())\n",
    "\n",
    "    # Display the similarity DataFrame with node names\n",
    "similarity_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b198c86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f1f46a63",
   "metadata": {},
   "source": [
    "## Use of the predicted links to create the relationships in the database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb87b887",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assuming we have the predicted links as a DataFrame 'predicted_links_df'\n",
    "with driver.session() as session:\n",
    "    for _, row in predicted_links_df.iterrows():\n",
    "        start_node_id = row['component_id']\n",
    "        end_node_id = row['machine_state_id']\n",
    "        \n",
    "        query = f\"\"\"\n",
    "        MATCH (c:Component), (ms:Machine_State)\n",
    "        WHERE id(c) = {start_node_id} AND id(ms) = {end_node_id}\n",
    "        MERGE (c)-[:leads_to]->(ms)\n",
    "        \"\"\"\n",
    "        session.run(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77b90ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c9e51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a91cf5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f2b48d8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a57b262",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c45482",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf0d28a3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The dataset is empty. Please check your Neo4j query and data.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Check if the DataFrame is empty\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[1;32m---> 14\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe dataset is empty. Please check your Neo4j query and data.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Prepare the target variable ('link' column)\u001b[39;00m\n\u001b[0;32m     17\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlink\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "\u001b[1;31mValueError\u001b[0m: The dataset is empty. Please check your Neo4j query and data."
     ]
    }
   ],
   "source": [
    "with driver.session() as session:\n",
    "    # Retrieve all components and machine states\n",
    "    query = \"\"\"\n",
    "    MATCH (c:Component), (ms:Machine_State)\n",
    "    RETURN id(c) AS component_id, id(ms) AS machine_state_id\n",
    "    \"\"\"\n",
    "    result = session.run(query)\n",
    "\n",
    "    # Convert the query result to a pandas DataFrame\n",
    "    df = pd.DataFrame(result.data())\n",
    "\n",
    "# Check if the DataFrame is empty\n",
    "if df.empty:\n",
    "    raise ValueError(\"The dataset is empty. Please check your Neo4j query and data.\")\n",
    "\n",
    "# Prepare the target variable ('link' column)\n",
    "df['link'] = 1\n",
    "\n",
    "# Split the dataset into training and testing sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
