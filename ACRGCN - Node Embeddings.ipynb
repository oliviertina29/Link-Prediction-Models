{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e5ae9fc",
   "metadata": {},
   "source": [
    "## Installing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90fe7af4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install node2vec\n",
    "#!pip install neo4j\n",
    "#!pip install --upgrade networkx\n",
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76668d75",
   "metadata": {},
   "source": [
    "## Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c2cdb896",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity, euclidean_distances, manhattan_distances\n",
    "from neo4j import GraphDatabase\n",
    "from node2vec import Node2Vec\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim.downloader as api\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "#from tensorflow.keras.layers import BatchNormalization, Dropout, ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04db0339",
   "metadata": {},
   "source": [
    "## Connecting to the neo4j database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "a4b88be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"OLIV00%%\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff062521",
   "metadata": {},
   "source": [
    "## Loading of the KG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "be9f6e6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node ID: 0\n",
      "Node Name: Couple unbalance\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 1\n",
      "Node Name: Dynamic unbalance\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 2\n",
      "Node Name: Overhung unbalance\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 3\n",
      "Node Name: Structural looseness\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 4\n",
      "Node Name: Angular misalignment\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 5\n",
      "Node Name: General misalignment\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 6\n",
      "Node Name: Parallel misalignment\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 7\n",
      "Node Name: Mechanical loosenes\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 8\n",
      "Node Name: Component loosenes\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 9\n",
      "Node Name: Bearing Lubrication Fault\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 10\n",
      "Node Name: Excessive gear\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 11\n",
      "Node Name: Excessive loading\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 12\n",
      "Node Name: Mechanical misalignment\n",
      "Node Type: Explanation\n",
      "\n",
      "Node ID: 13\n",
      "Node Name: Pump\n",
      "Node Type: Component\n",
      "\n",
      "Node ID: 14\n",
      "Node Name: Fan\n",
      "Node Type: Component\n",
      "\n",
      "Node ID: 15\n",
      "Node Name: Engine\n",
      "Node Type: Component\n",
      "\n",
      "Node ID: 16\n",
      "Node Name: Normal\n",
      "Node Type: Normal\n",
      "\n",
      "Node ID: 17\n",
      "Node Name: Imbalance\n",
      "Node Type: Imbalance\n",
      "\n",
      "Node ID: 18\n",
      "Node Name: Structural fault\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 19\n",
      "Node Name: Misalignment\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 20\n",
      "Node Name: looseness\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 21\n",
      "Node Name: Bearing Fault\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 22\n",
      "Node Name: Gear Fault\n",
      "Node Type: Failure\n",
      "\n",
      "Node ID: 23\n",
      "Node Name: Machine_OCP\n",
      "Node Type: Engine_pump\n",
      "\n",
      "Node ID: 29\n",
      "Node Name: Static unbalance\n",
      "Node Type: Explanation\n",
      "\n"
     ]
    }
   ],
   "source": [
    "graph = nx.Graph()\n",
    "\n",
    "with driver.session() as session:\n",
    "    # Récupérer les nœuds avec leur nom et type\n",
    "    nodes_query = \"MATCH (n) RETURN ID(n) AS id, n.name AS name, n.type AS type\"\n",
    "    nodes_result = session.run(nodes_query)\n",
    "\n",
    "    # Parcourir les résultats et ajouter les nœuds au graphe\n",
    "    for record in nodes_result:\n",
    "        node_id = record[\"id\"]\n",
    "        node_name = record[\"name\"]\n",
    "        node_type = record[\"type\"]\n",
    "        if node_id is not None:\n",
    "            graph.add_node(node_id, name=node_name, type=node_type)\n",
    "\n",
    "    # Récupérer les relations\n",
    "    relations_query = \"MATCH ()-[r]->() RETURN ID(startNode(r)) AS source_id, ID(endNode(r)) AS target_id\"\n",
    "    relations_result = session.run(relations_query)\n",
    "\n",
    "    # Ajouter les relations entre les nœuds\n",
    "    for record in relations_result:\n",
    "        source_node_id = record[\"source_id\"]\n",
    "        target_node_id = record[\"target_id\"]\n",
    "        if source_node_id is not None and target_node_id is not None:\n",
    "            graph.add_edge(source_node_id, target_node_id)\n",
    "\n",
    "# Afficher les informations des nœuds\n",
    "for node_id, node_data in graph.nodes(data=True):\n",
    "    print(\"Node ID:\", node_id)\n",
    "    print(\"Node Name:\", node_data.get(\"name\"))\n",
    "    print(\"Node Type:\", node_data.get(\"type\"))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d9cda3",
   "metadata": {},
   "source": [
    "## Features extraction from nodes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b3f02caf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 0, 'name': 'Couple unbalance', 'type': 'Explanation'}\n"
     ]
    }
   ],
   "source": [
    "# Préparer les caractéristiques des nœuds\n",
    "node_features = []\n",
    "\n",
    "# Récupérer les attributs \"id\", \"name\" et \"type\" des nœuds dans le graphe\n",
    "for node_id in graph.nodes:\n",
    "    node_data = graph.nodes[node_id]\n",
    "    node_feature = {\n",
    "        \"id\": node_id,\n",
    "        \"name\": node_data[\"name\"],\n",
    "        \"type\": node_data[\"type\"]\n",
    "    }\n",
    "    node_features.append(node_feature)\n",
    "\n",
    "# Convertir les caractéristiques des nœuds en un tableau numpy\n",
    "#X = np.array([(node[\"id\"], node[\"name\"], node[\"type\"]) for node in node_features])\n",
    "X = np.array(node_features)\n",
    "print(X[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2778eeaf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d7436790534e410586cb8066abb01832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Computing transition probabilities:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Exécutez l'algorithme Node2Vec\n",
    "node2vec = Node2Vec(graph, dimensions=16, walk_length=15, num_walks=60, workers=4)\n",
    "\n",
    "# Entraînez le modèle pour apprendre les embeddings\n",
    "model = node2vec.fit(window=10, min_count=1)\n",
    "\n",
    "# Obtenez les embeddings pour tous les nœuds du graphe\n",
    "embeddings = [model.wv[str(node_id)] for node_id in graph.nodes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f8e1dd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25, 16)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_array_to_matrix(array):\n",
    "    \"\"\"Transforms an array of arrays into a matrix.\"\"\"\n",
    "    matrix = np.array(array)\n",
    "    matrix = matrix.reshape(matrix.shape[0], -1)\n",
    "    return matrix\n",
    "\n",
    "X = transform_array_to_matrix(embeddings)\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e2c3fb1",
   "metadata": {},
   "source": [
    "## Attention-based Compressed Relational Graph Convolutional Network (ACRGCN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bef700ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ACRGCN(G, X, L, Decoder_layer):\n",
    "    '''\n",
    "    G : Knowledge graph\n",
    "    X : nodes features (embeddings of the nodes)\n",
    "    L : Encoder layer number\n",
    "    Decoder_layer : Decoder layer number\n",
    "    '''\n",
    "    H = X\n",
    "    for i in range(L):   \n",
    "        H = RGCN(H, G)\n",
    "        H = BN(H)\n",
    "        H = ReLU(H)\n",
    "        if i < L-1:\n",
    "            H = Dropout(H)\n",
    "    H_maxlayer = GAT(H, G)\n",
    "    \n",
    "    for i in range(Decoder_layer, 0, -1):\n",
    "        H = DeRGCN(H_maxlayer, G)\n",
    "        H = BN(H)\n",
    "        H = ReLU(H)\n",
    "        if i > 1:\n",
    "            H = Dropout(H)\n",
    "        H = np.concatenate((H, H_maxlayer), axis=1)\n",
    "    \n",
    "    E_candidate = ScoreDistMult(H)\n",
    "    \n",
    "    return E_candidate\n",
    "\n",
    "\n",
    "def RGCN(H, G):\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    for layer in range(L):\n",
    "        W_layer = np.random.normal(0, 0.01, (H.shape[1], H.shape[1]))\n",
    "        H = H@W_layer\n",
    "        H = A.dot(H)\n",
    "        H = np.maximum(H, 0)\n",
    "    return H\n",
    "\n",
    "\n",
    "def BN(H):\n",
    "    # Batch Normalization operation\n",
    "    scaler = StandardScaler()\n",
    "    H = scaler.fit_transform(H)\n",
    "    return H\n",
    "\n",
    "\n",
    "def ReLU(H):\n",
    "    # ReLU activation function\n",
    "    return np.maximum(H, 0)\n",
    "\n",
    "\n",
    "def Dropout(H, p=0.5):\n",
    "    # Dropout operation\n",
    "    mask = np.random.binomial(1, p, size=H.shape)\n",
    "    H = H * mask / p\n",
    "    return H\n",
    "\n",
    "\n",
    "def GAT(H, G, lambda_val=0.2):\n",
    "    num_nodes, feature_dim = H.shape\n",
    "    H = torch.tensor(H, dtype=torch.float32)\n",
    "    \n",
    "    # Initialize attention weight matrix (W_a) with random values\n",
    "    W_a = torch.randn(feature_dim, feature_dim, dtype=torch.float32)\n",
    "    \n",
    "    # Convert lambda_val to a PyTorch tensor with an extra dimension\n",
    "    lambda_val = torch.tensor([lambda_val], dtype=torch.float32)\n",
    "    H_a = torch.zeros_like(H)\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        neighbors = G[i]  # Get the neighbors of the ith node\n",
    "        num_neighbors = len(neighbors)\n",
    "        alpha = torch.zeros(num_neighbors)\n",
    "        \n",
    "        for j, neighbor_idx in enumerate(neighbors):\n",
    "            concat_features = torch.cat((torch.matmul(W_a, H[i]), torch.matmul(W_a, H[neighbor_idx])))\n",
    "            # Ensure lambda_val has the same shape as concat_features for element-wise operations\n",
    "            expanded_lambda_val = lambda_val.expand_as(concat_features)\n",
    "            alpha[j] = torch.exp(F.leaky_relu(torch.matmul(expanded_lambda_val, concat_features)))\n",
    "            \n",
    "        alpha = F.softmax(alpha, dim=0)\n",
    "        \n",
    "        for j, neighbor_idx in enumerate(neighbors):\n",
    "            H_a[i] += alpha[j] * torch.matmul(W_a, H[neighbor_idx])\n",
    "            \n",
    "    H_a = torch.sigmoid(H_a)\n",
    "    return H_a\n",
    "\n",
    "\n",
    "def DeRGCN(H, G):\n",
    "    A = nx.adjacency_matrix(G)\n",
    "    W_layer = np.random.normal(0, 0.01, (H.shape[1], H.shape[1]))\n",
    "    H = H@W_layer\n",
    "    H = A.T.dot(H)\n",
    "    H = np.maximum(H, 0)\n",
    "    return H\n",
    "\n",
    "\n",
    "def ScoreDistMult(H):\n",
    "    # Score calculation using DistMult\n",
    "    scores = np.dot(H, np.transpose(H))\n",
    "    return scores\n",
    "\n",
    "\n",
    "def Sort(scores):\n",
    "    # Sort the scores in descending order\n",
    "    sorted_indices = np.argsort(scores)[::-1] \n",
    "    sorted_scores = scores[sorted_indices]\n",
    "    return sorted_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4d77ac1",
   "metadata": {},
   "source": [
    "## Model execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "649bfc81",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 29 is out of bounds for dimension 0 with size 25",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m L \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m  \u001b[38;5;66;03m# Encoder layer number\u001b[39;00m\n\u001b[0;32m      3\u001b[0m Decoder_layer \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2\u001b[39m  \u001b[38;5;66;03m# Decoder layer number\u001b[39;00m\n\u001b[1;32m----> 4\u001b[0m E_candidates \u001b[38;5;241m=\u001b[39m ACRGCN(graph, X, L, Decoder_layer)\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Afficher les résultats\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28mprint\u001b[39m(E_candidates)\n",
      "Cell \u001b[1;32mIn[21], line 15\u001b[0m, in \u001b[0;36mACRGCN\u001b[1;34m(G, X, L, Decoder_layer)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m<\u001b[39m L\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m     14\u001b[0m         H \u001b[38;5;241m=\u001b[39m Dropout(H)\n\u001b[1;32m---> 15\u001b[0m H_maxlayer \u001b[38;5;241m=\u001b[39m GAT(H, G)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(Decoder_layer, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m):\n\u001b[0;32m     18\u001b[0m     H \u001b[38;5;241m=\u001b[39m DeRGCN(H_maxlayer, G)\n",
      "Cell \u001b[1;32mIn[21], line 76\u001b[0m, in \u001b[0;36mGAT\u001b[1;34m(H, G, lambda_val)\u001b[0m\n\u001b[0;32m     73\u001b[0m alpha \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros(num_neighbors)\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m j, neighbor_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(neighbors):\n\u001b[1;32m---> 76\u001b[0m     concat_features \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat((torch\u001b[38;5;241m.\u001b[39mmatmul(W_a, H[i]), torch\u001b[38;5;241m.\u001b[39mmatmul(W_a, H[neighbor_idx])))\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;66;03m# Ensure lambda_val has the same shape as concat_features for element-wise operations\u001b[39;00m\n\u001b[0;32m     78\u001b[0m     expanded_lambda_val \u001b[38;5;241m=\u001b[39m lambda_val\u001b[38;5;241m.\u001b[39mexpand_as(concat_features)\n",
      "\u001b[1;31mIndexError\u001b[0m: index 29 is out of bounds for dimension 0 with size 25"
     ]
    }
   ],
   "source": [
    "# Appliquer l'algorithme ACRGCN\n",
    "L = 3  # Encoder layer number\n",
    "Decoder_layer = 2  # Decoder layer number\n",
    "E_candidates = ACRGCN(graph, X, L, Decoder_layer)\n",
    "\n",
    "# Afficher les résultats\n",
    "print(E_candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47041208",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'E_candidates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m E_candidates\u001b[38;5;241m.\u001b[39mshape\n",
      "\u001b[1;31mNameError\u001b[0m: name 'E_candidates' is not defined"
     ]
    }
   ],
   "source": [
    "E_candidates.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10e25998",
   "metadata": {},
   "source": [
    "## Close session and driver at the end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "459b2994",
   "metadata": {},
   "outputs": [],
   "source": [
    "session.close()\n",
    "driver.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "215dcf29",
   "metadata": {},
   "outputs": [],
   "source": [
    "[0] * 4"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
