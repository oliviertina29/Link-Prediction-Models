{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f18c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio\n",
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ebfe8",
   "metadata": {},
   "source": [
    "### Importing  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1b3052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olivi\\anaconda3\\envs\\Py_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import GraphSAGE\n",
    "from stellargraph.data import UnsupervisedSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e5711",
   "metadata": {},
   "source": [
    "### Connect to the database and fetch graph data from Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c505ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Neo4j database\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"OLIV00%%\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Function to fetch graph data from Neo4j\n",
    "def fetch_graph_data():\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (n1)-[r]->(n2) RETURN id(n1) AS start, id(n2) AS end, type(r) AS relationship\"\n",
    "        )\n",
    "        data = [(record[\"start\"], record[\"end\"], record[\"relationship\"]) for record in result]\n",
    "    return data\n",
    "\n",
    "# Load graph data\n",
    "graph_data = fetch_graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f052a41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(23, 15, 'Component'),\n",
       " (17, 29, 'Caused_by'),\n",
       " (17, 0, 'Caused_by'),\n",
       " (17, 1, 'Caused_by'),\n",
       " (17, 2, 'Caused_by'),\n",
       " (18, 3, 'Caused_by'),\n",
       " (19, 4, 'Caused_by'),\n",
       " (19, 5, 'Caused_by'),\n",
       " (19, 6, 'Caused_by'),\n",
       " (20, 7, 'Caused_by'),\n",
       " (20, 8, 'Caused_by'),\n",
       " (21, 9, 'Caused_by'),\n",
       " (22, 10, 'Caused_by'),\n",
       " (22, 11, 'Caused_by'),\n",
       " (22, 12, 'Caused_by'),\n",
       " (23, 13, 'Component'),\n",
       " (23, 14, 'Component')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "train_data, test_data = train_test_split(graph_data, test_size=0.5, random_state=42)\n",
    "\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85325a0",
   "metadata": {},
   "source": [
    "# Graph Convolution Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd0c2b",
   "metadata": {},
   "source": [
    "### Convert the graph data into adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f2c9459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 1 1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create a directed graph using NetworkX\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "for start, end, relationship in graph_data:\n",
    "    G.add_node(start)\n",
    "    G.add_node(end)\n",
    "    G.add_edge(start, end, relationship=relationship)\n",
    "\n",
    "# Create the adjacency matrix\n",
    "adj_matrix = nx.to_numpy_matrix(G, dtype=int)\n",
    "\n",
    "# Get the node order in the adjacency matrix\n",
    "node_order = sorted(G.nodes())\n",
    "\n",
    "# Create a dictionary to map node IDs to indices in the adjacency matrix\n",
    "node_index_map = {node_id: index for index, node_id in enumerate(node_order)}\n",
    "\n",
    "# Rearrange the adjacency matrix based on the node order\n",
    "adj_matrix_reordered = np.array([[adj_matrix[node_index_map[start], node_index_map[end]] for end in node_order] for start in node_order])\n",
    "\n",
    "# Print the adjacency matrix\n",
    "print(adj_matrix_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "52836518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix shape : (24, 24)\n"
     ]
    }
   ],
   "source": [
    "# Print the adjacency matrix shape\n",
    "print(f\"Adjacency matrix shape : {adj_matrix_reordered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391738dd",
   "metadata": {},
   "source": [
    "### Nodes feature  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "34046bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the adjacency matrix to a tensor\n",
    "adj_matrix_tensor = torch.tensor(adj_matrix_reordered, dtype=torch.float)\n",
    "\n",
    "# Create an identity matrix to represent node features (assuming no node features, only structural information)\n",
    "num_nodes = adj_matrix_tensor.shape[0]\n",
    "identity_matrix = torch.eye(num_nodes)\n",
    "\n",
    "# Concatenate the adjacency matrix and identity matrix as node features\n",
    "node_features = torch.cat((adj_matrix_tensor, identity_matrix), dim=1)\n",
    "\n",
    "# Create the edge index tensor for PyTorch Geometric\n",
    "edge_index = torch.tensor(np.array(G.edges()).T, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d837b53",
   "metadata": {},
   "source": [
    "### Model building\n",
    "### DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e4cf7bf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 3.4803035259246826\n",
      "Epoch: 10, Loss: 2.547050714492798\n",
      "Epoch: 20, Loss: 1.4371734857559204\n",
      "Epoch: 30, Loss: 1.0413086414337158\n",
      "Epoch: 40, Loss: 0.9984414577484131\n",
      "Epoch: 50, Loss: 0.9928731322288513\n",
      "Epoch: 60, Loss: 0.9915652275085449\n",
      "Epoch: 70, Loss: 0.99104905128479\n",
      "Epoch: 80, Loss: 0.9908137321472168\n",
      "Epoch: 90, Loss: 0.9906622767448425\n",
      "Epoch: 100, Loss: 0.990551769733429\n",
      "Epoch: 110, Loss: 0.9904589056968689\n",
      "Epoch: 120, Loss: 0.9903779029846191\n",
      "Epoch: 130, Loss: 0.990305483341217\n",
      "Epoch: 140, Loss: 0.9902400970458984\n",
      "Epoch: 150, Loss: 0.9901806116104126\n"
     ]
    }
   ],
   "source": [
    "# Define the Graph Convolutional Network (GCN) model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert the data to PyTorch Geometric Data object\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss = criterion(output[data.edge_index[0]], data.edge_index[1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# You can now use the trained model to make predictions on new data or perform link prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd0305",
   "metadata": {},
   "source": [
    "### New links prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "02d17bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Function to predict new links using the trained model\n",
    "def predict_new_links(model, data, new_edges):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index)\n",
    "        predicted_labels = output[new_edges[0]]\n",
    "        predicted_labels = (predicted_labels >= 0.5).int()  # Threshold predictions\n",
    "    return predicted_labels\n",
    "\n",
    "# Predict new links for a set of new edge indices\n",
    "new_edges = torch.tensor([[13, 17], [14, 17], [15, 17]], dtype=torch.long).t()  # Format: (start_nodes, end_nodes)\n",
    "predictions = predict_new_links(model, data, new_edges)\n",
    "\n",
    "# The predictions will be a tensor containing 0s and 1s, where 1 indicates - link and 0 indicates - no link.\n",
    "print(\"Predicted link presence:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663cd43",
   "metadata": {},
   "source": [
    "### DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a1eb38e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 0.8947755694389343\n",
      "Epoch: 10, Loss: -8.375316619873047\n",
      "Epoch: 20, Loss: -29.453100204467773\n",
      "Epoch: 30, Loss: -68.98267364501953\n",
      "Epoch: 40, Loss: -131.4411163330078\n",
      "Epoch: 50, Loss: -220.2678985595703\n",
      "Epoch: 60, Loss: -338.01434326171875\n",
      "Epoch: 70, Loss: -486.4073486328125\n",
      "Epoch: 80, Loss: -667.0595703125\n",
      "Epoch: 90, Loss: -881.8046264648438\n",
      "Epoch: 100, Loss: -1131.091796875\n",
      "Epoch: 110, Loss: -1415.167724609375\n",
      "Epoch: 120, Loss: -1734.1153564453125\n",
      "Epoch: 130, Loss: -2087.921630859375\n",
      "Epoch: 140, Loss: -2476.520751953125\n",
      "Epoch: 150, Loss: -2899.814208984375\n"
     ]
    }
   ],
   "source": [
    "# Define the Graph Convolutional Network (GCN) model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv2 = nn.Linear(hidden_dim, 1)  # Output dimension changed to 1 for binary classification\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "model = GCN(input_dim, hidden_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert the data to PyTorch Geometric Data object\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index).squeeze()  # Squeeze the output to remove the singleton dimension\n",
    "    loss = criterion(output[data.edge_index[0]], data.edge_index[1].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4bd63",
   "metadata": {},
   "source": [
    "### New links prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a6b03180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Function to predict new links using the trained model\n",
    "def predict_new_links(model, data, new_edges):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index)\n",
    "        predicted_labels = output[new_edges[0]]\n",
    "        predicted_labels = (predicted_labels >= 0.5).int()  # Threshold predictions\n",
    "    return predicted_labels\n",
    "\n",
    "# Predict new links for a set of new edge indices\n",
    "new_edges = torch.tensor([[13, 17], [14, 17], [15, 17]], dtype=torch.long).t()  # Format: (start_nodes, end_nodes)\n",
    "predictions = predict_new_links(model, data, new_edges)\n",
    "\n",
    "# The predictions will be a tensor containing 0s and 1s, where 1 indicates - link and 0 indicates - no link.\n",
    "print(\"Predicted link presence:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e27b39",
   "metadata": {},
   "source": [
    "# Relational Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f13d8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_relations=1, num_bases=30):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.conv1 = RGCNConv(input_dim, hidden_dim, num_relations, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations, num_bases=num_bases)\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = torch.relu(self.conv1(x, edge_index, edge_type))\n",
    "        x = torch.relu(self.conv2(x, edge_index, edge_type))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "model = RGCN(input_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e32d63f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'edge_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'edge_type'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_11148\\1079836226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_type\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Pass the edge_type to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \"root folder and try again.\")\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             raise AttributeError(\n\u001b[1;32m---> 82\u001b[1;33m                 f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'edge_type'"
     ]
    }
   ],
   "source": [
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index, data.edge_type)  # Pass the edge_type to the model\n",
    "    loss = criterion(output[data.edge_index[0]], data.edge_index[1].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
