{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f18c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio\n",
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ebfe8",
   "metadata": {},
   "source": [
    "### Importing  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1b3052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import GraphSAGE\n",
    "from stellargraph.data import UnsupervisedSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e5711",
   "metadata": {},
   "source": [
    "### Connect to the database and fetch graph data from Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "b9c505ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Neo4j database\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"OLIV00%%\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Function to fetch graph data from Neo4j\n",
    "def fetch_graph_data():\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (n1)-[r]->(n2) RETURN id(n1) AS start, id(n2) AS end, type(r) AS relationship\"\n",
    "        )\n",
    "        data = [(record[\"start\"], record[\"end\"], record[\"relationship\"]) for record in result]\n",
    "    return data\n",
    "\n",
    "# Load graph data\n",
    "graph_data = fetch_graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "f052a41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 7, 'interval'),\n",
       " (32, 8, 'interval'),\n",
       " (32, 9, 'interval'),\n",
       " (32, 10, 'interval'),\n",
       " (32, 11, 'interval'),\n",
       " (32, 12, 'interval'),\n",
       " (32, 13, 'interval'),\n",
       " (0, 45, 'min'),\n",
       " (1, 47, 'min'),\n",
       " (2, 49, 'min'),\n",
       " (3, 51, 'min'),\n",
       " (4, 53, 'min'),\n",
       " (5, 55, 'min'),\n",
       " (6, 57, 'min'),\n",
       " (51, 35, 'Probability of : 55% '),\n",
       " (45, 34, 'Probability of : 30% '),\n",
       " (46, 34, 'Probability of : 30% '),\n",
       " (0, 46, 'max'),\n",
       " (1, 48, 'max'),\n",
       " (2, 50, 'max'),\n",
       " (3, 52, 'max'),\n",
       " (4, 54, 'max'),\n",
       " (5, 56, 'max'),\n",
       " (6, 58, 'max'),\n",
       " (7, 45, 'min'),\n",
       " (8, 47, 'min'),\n",
       " (9, 49, 'min'),\n",
       " (10, 51, 'min'),\n",
       " (11, 53, 'min'),\n",
       " (12, 55, 'min'),\n",
       " (13, 57, 'min'),\n",
       " (47, 35, 'Probability of : 100% '),\n",
       " (48, 35, 'Probability of : 100% '),\n",
       " (49, 35, 'Probability of : 100% '),\n",
       " (40, 31, 'Measuring'),\n",
       " (40, 32, 'Measuring'),\n",
       " (41, 31, 'Measuring'),\n",
       " (41, 32, 'Measuring'),\n",
       " (42, 31, 'Measuring'),\n",
       " (42, 32, 'Measuring'),\n",
       " (43, 31, 'Measuring'),\n",
       " (43, 32, 'Measuring'),\n",
       " (57, 37, 'Probability of  90%'),\n",
       " (52, 35, 'Probability of : 90% '),\n",
       " (58, 38, 'Probability of  30%'),\n",
       " (50, 35, 'Probability of : 98%'),\n",
       " (52, 36, 'Probability of  10%'),\n",
       " (57, 36, 'Probability of  10%'),\n",
       " (53, 36, 'Probability of  98%'),\n",
       " (45, 33, 'Probability of : 70% '),\n",
       " (46, 33, 'Probability of : 70% '),\n",
       " (28, 40, 'Installed'),\n",
       " (29, 40, 'Installed'),\n",
       " (30, 40, 'Installed'),\n",
       " (28, 41, 'Installed'),\n",
       " (29, 41, 'Installed'),\n",
       " (30, 41, 'Installed'),\n",
       " (28, 42, 'Installed'),\n",
       " (29, 42, 'Installed'),\n",
       " (30, 42, 'Installed'),\n",
       " (28, 43, 'Installed'),\n",
       " (29, 43, 'Installed'),\n",
       " (30, 43, 'Installed'),\n",
       " (7, 46, 'max'),\n",
       " (8, 48, 'max'),\n",
       " (9, 50, 'max'),\n",
       " (10, 52, 'max'),\n",
       " (11, 54, 'max'),\n",
       " (12, 56, 'max'),\n",
       " (13, 58, 'max'),\n",
       " (44, 28, 'Component'),\n",
       " (44, 29, 'Component'),\n",
       " (44, 30, 'Component'),\n",
       " (55, 37, 'Probability of  100%'),\n",
       " (34, 14, 'Caused_by'),\n",
       " (34, 15, 'Caused_by'),\n",
       " (34, 16, 'Caused_by'),\n",
       " (34, 17, 'Caused_by'),\n",
       " (35, 18, 'Caused_by'),\n",
       " (36, 19, 'Caused_by'),\n",
       " (36, 20, 'Caused_by'),\n",
       " (36, 21, 'Caused_by'),\n",
       " (37, 22, 'Caused_by'),\n",
       " (37, 23, 'Caused_by'),\n",
       " (38, 24, 'Caused_by'),\n",
       " (39, 25, 'Caused_by'),\n",
       " (39, 26, 'Caused_by'),\n",
       " (39, 27, 'Caused_by'),\n",
       " (58, 39, 'Probability of  70%'),\n",
       " (50, 36, 'Probability of : 2%'),\n",
       " (53, 37, 'Probability of  2%'),\n",
       " (31, 0, 'interval'),\n",
       " (31, 1, 'interval'),\n",
       " (31, 2, 'interval'),\n",
       " (31, 3, 'interval'),\n",
       " (31, 4, 'interval'),\n",
       " (31, 5, 'interval'),\n",
       " (31, 6, 'interval'),\n",
       " (51, 36, 'Probability of  45%'),\n",
       " (54, 37, 'Probability of  25%'),\n",
       " (56, 37, 'Probability of  25%'),\n",
       " (54, 38, 'Probability of  75%'),\n",
       " (56, 38, 'Probability of  75%')]"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "train_data, test_data = train_test_split(graph_data, test_size=0.5, random_state=42)\n",
    "\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3da407c",
   "metadata": {},
   "source": [
    "# Adamic Adar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "baafddf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform Adamic-Adar link prediction\n",
    "def adamic_adar_link_prediction(node1_id, node2_id):\n",
    "    with driver.session() as session:\n",
    "        query = (\n",
    "            f\"MATCH (n1)-[:COMMON]->(common_node)\"\n",
    "            f\"<-[:COMMON]-(n2) WHERE id(n1)={node1_id} AND id(n2)={node2_id} \"\n",
    "            \"RETURN count(common_node) AS adamic_adar_score\"\n",
    "        )\n",
    "        result = session.run(query)\n",
    "        return result.single()[\"adamic_adar_score\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9206e3",
   "metadata": {},
   "source": [
    "### Adamic Adar link prediction model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "03f844fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.00\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the link prediction model\n",
    "def evaluate_link_prediction():\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    for node1_id, node2_id, _ in test_data:\n",
    "        adamic_adar_score = adamic_adar_link_prediction(node1_id, node2_id)\n",
    "        y_true.append(1)  # Link exists\n",
    "        y_pred.append(1 if adamic_adar_score > 0 else 0)  # Predict link existence based on score\n",
    "\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    print(f\"Accuracy: {accuracy:.2f}\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    evaluate_link_prediction()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85325a0",
   "metadata": {},
   "source": [
    "# Graph Convolution Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd0c2b",
   "metadata": {},
   "source": [
    "### Convert the graph data into adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "1f2c9459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create a directed graph using NetworkX\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "for start, end, relationship in graph_data:\n",
    "    G.add_node(start)\n",
    "    G.add_node(end)\n",
    "    G.add_edge(start, end, relationship=relationship)\n",
    "\n",
    "# Create the adjacency matrix\n",
    "adj_matrix = nx.to_numpy_matrix(G, dtype=int)\n",
    "\n",
    "# Get the node order in the adjacency matrix\n",
    "node_order = sorted(G.nodes())\n",
    "\n",
    "# Create a dictionary to map node IDs to indices in the adjacency matrix\n",
    "node_index_map = {node_id: index for index, node_id in enumerate(node_order)}\n",
    "\n",
    "# Rearrange the adjacency matrix based on the node order\n",
    "adj_matrix_reordered = np.array([[adj_matrix[node_index_map[start], node_index_map[end]] for end in node_order] for start in node_order])\n",
    "\n",
    "# Print the adjacency matrix\n",
    "print(adj_matrix_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "52836518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix shape : (59, 59)\n"
     ]
    }
   ],
   "source": [
    "# Print the adjacency matrix shape\n",
    "print(f\"Adjacency matrix shape : {adj_matrix_reordered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391738dd",
   "metadata": {},
   "source": [
    "### Nodes feature  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "34046bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the adjacency matrix to a tensor\n",
    "adj_matrix_tensor = torch.tensor(adj_matrix_reordered, dtype=torch.float)\n",
    "\n",
    "# Create an identity matrix to represent node features (assuming no node features, only structural information)\n",
    "num_nodes = adj_matrix_tensor.shape[0]\n",
    "identity_matrix = torch.eye(num_nodes)\n",
    "\n",
    "# Concatenate the adjacency matrix and identity matrix as node features\n",
    "node_features = torch.cat((adj_matrix_tensor, identity_matrix), dim=1)\n",
    "\n",
    "# Create the edge index tensor for PyTorch Geometric\n",
    "edge_index = torch.tensor(np.array(G.edges()).T, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d837b53",
   "metadata": {},
   "source": [
    "### Model building\n",
    "### DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "e4cf7bf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 45 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16332\\1927881694.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     29\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 31\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     32\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     33\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3026\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 45 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Define the Graph Convolutional Network (GCN) model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert the data to PyTorch Geometric Data object\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss = criterion(output[data.edge_index[0]], data.edge_index[1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# You can now use the trained model to make predictions on new data or perform link prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663cd43",
   "metadata": {},
   "source": [
    "### DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a1eb38e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: -3.7078287601470947\n",
      "Epoch: 10, Loss: -62.52656555175781\n",
      "Epoch: 20, Loss: -226.18203735351562\n",
      "Epoch: 30, Loss: -552.5494384765625\n",
      "Epoch: 40, Loss: -1087.0587158203125\n",
      "Epoch: 50, Loss: -1861.30078125\n",
      "Epoch: 60, Loss: -2900.88037109375\n",
      "Epoch: 70, Loss: -4221.28466796875\n",
      "Epoch: 80, Loss: -5833.76953125\n",
      "Epoch: 90, Loss: -7744.30712890625\n",
      "Epoch: 100, Loss: -9956.375\n",
      "Epoch: 110, Loss: -12472.0390625\n",
      "Epoch: 120, Loss: -15292.298828125\n",
      "Epoch: 130, Loss: -18417.43359375\n",
      "Epoch: 140, Loss: -21847.212890625\n",
      "Epoch: 150, Loss: -25581.078125\n"
     ]
    }
   ],
   "source": [
    "# Define the Graph Convolutional Network (GCN) model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv2 = nn.Linear(hidden_dim, 1)  # Output dimension changed to 1 for binary classification\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "model = GCN(input_dim, hidden_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert the data to PyTorch Geometric Data object\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index).squeeze()  # Squeeze the output to remove the singleton dimension\n",
    "    loss = criterion(output[data.edge_index[0]], data.edge_index[1].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4bd63",
   "metadata": {},
   "source": [
    "### New links prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "a6b03180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Function to predict new links using the trained model\n",
    "def predict_new_links(model, data, new_edges):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index)\n",
    "        predicted_labels = output[new_edges[0]]\n",
    "        predicted_labels = (predicted_labels >= 0.5).int()  # Threshold predictions\n",
    "    return predicted_labels\n",
    "\n",
    "# Predict new links for a set of new edge indices\n",
    "new_edges = torch.tensor([[13, 17], [14, 17], [15, 17]], dtype=torch.long).t()  # Format: (start_nodes, end_nodes)\n",
    "predictions = predict_new_links(model, data, new_edges)\n",
    "\n",
    "# The predictions will be a tensor containing 0s and 1s, where 1 indicates - link and 0 indicates - no link.\n",
    "print(\"Predicted link presence:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "199a5c47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n",
      "\n",
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n",
      "\n",
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n",
      "\n",
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n",
      "\n",
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n",
      "\n",
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n",
      "\n",
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Predict new links for a set of new edge indices\n",
    "for i in range(33, 40):\n",
    "    new_edges = torch.tensor([[28, i], [29, i], [30, i]], dtype=torch.long).t()  # Format: (start_nodes, end_nodes)\n",
    "    predictions = predict_new_links(model, data, new_edges)\n",
    "\n",
    "    # The predictions will be a tensor containing 0s and 1s, where 1 indicates - link and 0 indicates - no link.\n",
    "    print(\"Predicted link presence:\")\n",
    "    print(predictions)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd4885a",
   "metadata": {},
   "source": [
    "### Model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9802bbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to perform evaluation on the test set\n",
    "def evaluate_model(model, data, edge_index, labels):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, edge_index)\n",
    "        predicted_labels = output.argmax(dim=1)  # Use argmax to get the predicted class labels\n",
    "\n",
    "    # Calculate accuracy\n",
    "    correct = (predicted_labels == labels).sum().item()\n",
    "    total = len(labels)\n",
    "    accuracy = correct / total\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "# Convert test data to PyTorch tensors\n",
    "test_edges = torch.tensor(test_edges, dtype=torch.long).t()\n",
    "test_labels = torch.tensor(test_labels, dtype=torch.long)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "test_accuracy = evaluate_model(model, data, test_edges, test_labels)\n",
    "\n",
    "print(\"Test Accuracy:\", test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e27b39",
   "metadata": {},
   "source": [
    "# Relational Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "f13d8a6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the Relational Graph Convolutional Network (R-GCN) model\n",
    "class RGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_relations=1, num_bases=30):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.conv1 = RGCNConv(input_dim, hidden_dim, num_relations, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations, num_bases=num_bases)\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x, edge_index, edge_type):\n",
    "        x = torch.relu(self.conv1(x, edge_index, edge_type))\n",
    "        x = torch.relu(self.conv2(x, edge_index, edge_type))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the R-GCN model\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "model = RGCN(input_dim, hidden_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "e32d63f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GlobalStorage' object has no attribute 'edge_type'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     78\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    103\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__getitem__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m->\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_mapping\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'edge_type'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_16332\\1079836226.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 12\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_type\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Pass the edge_type to the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     13\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     14\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\data\\data.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m    439\u001b[0m                 \u001b[1;34m\"dataset, remove the 'processed/' directory in the dataset's \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m                 \"root folder and try again.\")\n\u001b[1;32m--> 441\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_store\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\data\\storage.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     80\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             raise AttributeError(\n\u001b[1;32m---> 82\u001b[1;33m                 f\"'{self.__class__.__name__}' object has no attribute '{key}'\")\n\u001b[0m\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mAny\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'GlobalStorage' object has no attribute 'edge_type'"
     ]
    }
   ],
   "source": [
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert the data to PyTorch Geometric Data object\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index, data.edge_type)  # Pass the edge_type to the model\n",
    "    loss = criterion(output[data.edge_index[0]], data.edge_index[1].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c22f2d0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
