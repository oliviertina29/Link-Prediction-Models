{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51f18c41",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install torch torchvision torchaudio\n",
    "#!pip install torch-geometric"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc7ebfe8",
   "metadata": {},
   "source": [
    "### Importing  libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b1b3052",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\olivi\\anaconda3\\envs\\Py_env\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch_geometric.data import Data\n",
    "from torch_geometric.nn import RGCNConv\n",
    "\n",
    "from neo4j import GraphDatabase\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras import layers, optimizers, losses, metrics, Model\n",
    "\n",
    "from stellargraph import StellarGraph\n",
    "from stellargraph.layer import GraphSAGE\n",
    "from stellargraph.data import UnsupervisedSampler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d21e5711",
   "metadata": {},
   "source": [
    "### Connect to the database and fetch graph data from Neo4j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b9c505ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Connect to the Neo4j database\n",
    "uri = \"bolt://localhost:7687\"\n",
    "username = \"neo4j\"\n",
    "password = \"OLIV00%%\"\n",
    "\n",
    "driver = GraphDatabase.driver(uri, auth=(username, password))\n",
    "\n",
    "# Function to fetch graph data from Neo4j\n",
    "def fetch_graph_data():\n",
    "    with driver.session() as session:\n",
    "        result = session.run(\n",
    "            \"MATCH (n1)-[r]->(n2) RETURN id(n1) AS start, id(n2) AS end, type(r) AS relationship\"\n",
    "        )\n",
    "        data = [(record[\"start\"], record[\"end\"], record[\"relationship\"]) for record in result]\n",
    "    return data\n",
    "\n",
    "# Load graph data\n",
    "graph_data = fetch_graph_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f052a41b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(32, 7, 'interval'),\n",
       " (32, 8, 'interval'),\n",
       " (32, 9, 'interval'),\n",
       " (32, 10, 'interval'),\n",
       " (32, 11, 'interval'),\n",
       " (32, 12, 'interval'),\n",
       " (32, 13, 'interval'),\n",
       " (0, 45, 'min'),\n",
       " (1, 47, 'min'),\n",
       " (2, 49, 'min'),\n",
       " (3, 51, 'min'),\n",
       " (4, 53, 'min'),\n",
       " (5, 55, 'min'),\n",
       " (6, 57, 'min'),\n",
       " (51, 35, 'Probability of : 55% '),\n",
       " (45, 34, 'Probability of : 30% '),\n",
       " (46, 34, 'Probability of : 30% '),\n",
       " (0, 46, 'max'),\n",
       " (1, 48, 'max'),\n",
       " (2, 50, 'max'),\n",
       " (3, 52, 'max'),\n",
       " (4, 54, 'max'),\n",
       " (5, 56, 'max'),\n",
       " (6, 58, 'max'),\n",
       " (7, 45, 'min'),\n",
       " (8, 47, 'min'),\n",
       " (9, 49, 'min'),\n",
       " (10, 51, 'min'),\n",
       " (11, 53, 'min'),\n",
       " (12, 55, 'min'),\n",
       " (13, 57, 'min'),\n",
       " (47, 35, 'Probability of : 100% '),\n",
       " (48, 35, 'Probability of : 100% '),\n",
       " (49, 35, 'Probability of : 100% '),\n",
       " (40, 31, 'Measuring'),\n",
       " (40, 32, 'Measuring'),\n",
       " (41, 31, 'Measuring'),\n",
       " (41, 32, 'Measuring'),\n",
       " (42, 31, 'Measuring'),\n",
       " (42, 32, 'Measuring'),\n",
       " (43, 31, 'Measuring'),\n",
       " (43, 32, 'Measuring'),\n",
       " (57, 37, 'Probability of  90%'),\n",
       " (52, 35, 'Probability of : 90% '),\n",
       " (58, 38, 'Probability of  30%'),\n",
       " (50, 35, 'Probability of : 98%'),\n",
       " (52, 36, 'Probability of  10%'),\n",
       " (57, 36, 'Probability of  10%'),\n",
       " (53, 36, 'Probability of  98%'),\n",
       " (45, 33, 'Probability of : 70% '),\n",
       " (46, 33, 'Probability of : 70% '),\n",
       " (28, 40, 'Installed'),\n",
       " (29, 40, 'Installed'),\n",
       " (30, 40, 'Installed'),\n",
       " (28, 41, 'Installed'),\n",
       " (29, 41, 'Installed'),\n",
       " (30, 41, 'Installed'),\n",
       " (28, 42, 'Installed'),\n",
       " (29, 42, 'Installed'),\n",
       " (30, 42, 'Installed'),\n",
       " (28, 43, 'Installed'),\n",
       " (29, 43, 'Installed'),\n",
       " (30, 43, 'Installed'),\n",
       " (7, 46, 'max'),\n",
       " (8, 48, 'max'),\n",
       " (9, 50, 'max'),\n",
       " (10, 52, 'max'),\n",
       " (11, 54, 'max'),\n",
       " (12, 56, 'max'),\n",
       " (13, 58, 'max'),\n",
       " (44, 28, 'Component'),\n",
       " (44, 29, 'Component'),\n",
       " (44, 30, 'Component'),\n",
       " (55, 37, 'Probability of  100%'),\n",
       " (34, 14, 'Caused_by'),\n",
       " (34, 15, 'Caused_by'),\n",
       " (34, 16, 'Caused_by'),\n",
       " (34, 17, 'Caused_by'),\n",
       " (35, 18, 'Caused_by'),\n",
       " (36, 19, 'Caused_by'),\n",
       " (36, 20, 'Caused_by'),\n",
       " (36, 21, 'Caused_by'),\n",
       " (37, 22, 'Caused_by'),\n",
       " (37, 23, 'Caused_by'),\n",
       " (38, 24, 'Caused_by'),\n",
       " (39, 25, 'Caused_by'),\n",
       " (39, 26, 'Caused_by'),\n",
       " (39, 27, 'Caused_by'),\n",
       " (58, 39, 'Probability of  70%'),\n",
       " (50, 36, 'Probability of : 2%'),\n",
       " (53, 37, 'Probability of  2%'),\n",
       " (31, 0, 'interval'),\n",
       " (31, 1, 'interval'),\n",
       " (31, 2, 'interval'),\n",
       " (31, 3, 'interval'),\n",
       " (31, 4, 'interval'),\n",
       " (31, 5, 'interval'),\n",
       " (31, 6, 'interval'),\n",
       " (51, 36, 'Probability of  45%'),\n",
       " (54, 37, 'Probability of  25%'),\n",
       " (56, 37, 'Probability of  25%'),\n",
       " (54, 38, 'Probability of  75%'),\n",
       " (56, 38, 'Probability of  75%')]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split data into training and test sets\n",
    "train_data, test_data = train_test_split(graph_data, test_size=0.5, random_state=42)\n",
    "\n",
    "graph_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a85325a0",
   "metadata": {},
   "source": [
    "# Graph Convolution Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2dd0c2b",
   "metadata": {},
   "source": [
    "### Convert the graph data into adjacency matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1f2c9459",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1 1 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " ...\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "# Create a directed graph using NetworkX\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes and edges to the graph\n",
    "for start, end, relationship in graph_data:\n",
    "    G.add_node(start)\n",
    "    G.add_node(end)\n",
    "    G.add_edge(start, end, relationship=relationship)\n",
    "\n",
    "# Create the adjacency matrix\n",
    "adj_matrix = nx.to_numpy_matrix(G, dtype=int)\n",
    "\n",
    "# Get the node order in the adjacency matrix\n",
    "node_order = sorted(G.nodes())\n",
    "\n",
    "# Create a dictionary to map node IDs to indices in the adjacency matrix\n",
    "node_index_map = {node_id: index for index, node_id in enumerate(node_order)}\n",
    "\n",
    "# Rearrange the adjacency matrix based on the node order\n",
    "adj_matrix_reordered = np.array([[adj_matrix[node_index_map[start], node_index_map[end]] for end in node_order] for start in node_order])\n",
    "\n",
    "# Print the adjacency matrix\n",
    "print(adj_matrix_reordered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "52836518",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Adjacency matrix shape : (59, 59)\n"
     ]
    }
   ],
   "source": [
    "# Print the adjacency matrix shape\n",
    "print(f\"Adjacency matrix shape : {adj_matrix_reordered.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "391738dd",
   "metadata": {},
   "source": [
    "### Nodes feature  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "34046bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the adjacency matrix to a tensor\n",
    "adj_matrix_tensor = torch.tensor(adj_matrix_reordered, dtype=torch.float)\n",
    "\n",
    "# Create an identity matrix to represent node features (assuming no node features, only structural information)\n",
    "num_nodes = adj_matrix_tensor.shape[0]\n",
    "identity_matrix = torch.eye(num_nodes)\n",
    "\n",
    "# Concatenate the adjacency matrix and identity matrix as node features\n",
    "node_features = torch.cat((adj_matrix_tensor, identity_matrix), dim=1)\n",
    "\n",
    "# Create the edge index tensor for PyTorch Geometric\n",
    "edge_index = torch.tensor(np.array(G.edges()).T, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d837b53",
   "metadata": {},
   "source": [
    "### Model building\n",
    "### DIM = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e4cf7bf3",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "Target 45 is out of bounds.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_15068\\3811354067.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     33\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     34\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch\\nn\\modules\\loss.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, input, target)\u001b[0m\n\u001b[0;32m   1174\u001b[0m         return F.cross_entropy(input, target, weight=self.weight,\n\u001b[0;32m   1175\u001b[0m                                \u001b[0mignore_index\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduction\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1176\u001b[1;33m                                label_smoothing=self.label_smoothing)\n\u001b[0m\u001b[0;32m   1177\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1178\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch\\nn\\functional.py\u001b[0m in \u001b[0;36mcross_entropy\u001b[1;34m(input, target, weight, size_average, ignore_index, reduce, reduction, label_smoothing)\u001b[0m\n\u001b[0;32m   3024\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0msize_average\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mreduce\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3025\u001b[0m         \u001b[0mreduction\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlegacy_get_string\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msize_average\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreduce\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 3026\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcross_entropy_loss\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_Reduction\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_enum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mreduction\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mignore_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabel_smoothing\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   3027\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3028\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mIndexError\u001b[0m: Target 45 is out of bounds."
     ]
    }
   ],
   "source": [
    "# Define the Graph Convolutional Network (GCN) model\n",
    "\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = torch.relu(self.conv2(x))  # Apply ReLU activation\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "output_dim = 32\n",
    "model = GCN(input_dim, hidden_dim, output_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert the data to PyTorch Geometric Data object\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index)\n",
    "    loss = criterion(output[data.edge_index[0]], data.edge_index[1])\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n",
    "\n",
    "# You can now use the trained model to make predictions on new data or perform link prediction tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "defd0305",
   "metadata": {},
   "source": [
    "### New links prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "02d17bbc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted link presence:\n",
      "tensor([[0.0000, 0.1595, 0.0155, 0.0000, 0.0000, 0.0000, 0.0300, 0.1068, 0.0000,\n",
      "         0.0000, 0.0689, 0.0714, 0.0000, 0.0282, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1306, 0.1167, 0.0135, 0.0934, 0.0000, 0.0000, 0.0713, 0.0000, 0.0337,\n",
      "         0.0000, 0.0339, 0.0006, 0.0364, 0.0000],\n",
      "        [0.0000, 0.1163, 0.0428, 0.0016, 0.0000, 0.0000, 0.0255, 0.1203, 0.0000,\n",
      "         0.0000, 0.0431, 0.0904, 0.0000, 0.0455, 0.0000, 0.0000, 0.0341, 0.0000,\n",
      "         0.1004, 0.1215, 0.0386, 0.1173, 0.0000, 0.0000, 0.1116, 0.0000, 0.0000,\n",
      "         0.0000, 0.0123, 0.0000, 0.0585, 0.0000],\n",
      "        [0.0000, 0.1529, 0.0418, 0.0000, 0.0000, 0.0000, 0.0622, 0.1044, 0.0000,\n",
      "         0.0162, 0.0643, 0.0432, 0.0000, 0.0032, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "         0.1634, 0.0892, 0.0261, 0.1296, 0.0000, 0.0000, 0.0490, 0.0000, 0.0689,\n",
      "         0.0000, 0.0284, 0.0149, 0.0335, 0.0000]])\n"
     ]
    }
   ],
   "source": [
    "# Function to predict new links using the trained model\n",
    "def predict_new_links(model, data, new_edges):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index)\n",
    "        predicted_labels = output[new_edges[0]]\n",
    "    return predicted_labels\n",
    "\n",
    "# Predict new links for a set of new edge indices\n",
    "new_edges = torch.tensor([[13, 17], [14, 17], [15, 17]], dtype=torch.long).t()  # Format: (start_nodes, end_nodes)\n",
    "predictions = predict_new_links(model, data, new_edges)\n",
    "\n",
    "# The predictions will be a tensor containing 0s and 1s, where 1 indicates - link and 0 indicates - no link.\n",
    "print(\"Predicted link presence:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2663cd43",
   "metadata": {},
   "source": [
    "### DIM = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a1eb38e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 2.1347289085388184\n",
      "Epoch: 10, Loss: -6.453845977783203\n",
      "Epoch: 20, Loss: -25.460840225219727\n",
      "Epoch: 30, Loss: -63.25198745727539\n",
      "Epoch: 40, Loss: -125.97137451171875\n",
      "Epoch: 50, Loss: -218.64463806152344\n",
      "Epoch: 60, Loss: -345.2021179199219\n",
      "Epoch: 70, Loss: -507.74615478515625\n",
      "Epoch: 80, Loss: -707.5556030273438\n",
      "Epoch: 90, Loss: -945.3447265625\n",
      "Epoch: 100, Loss: -1221.5068359375\n",
      "Epoch: 110, Loss: -1536.230224609375\n",
      "Epoch: 120, Loss: -1889.5726318359375\n",
      "Epoch: 130, Loss: -2281.509765625\n",
      "Epoch: 140, Loss: -2711.9638671875\n",
      "Epoch: 150, Loss: -3180.820556640625\n"
     ]
    }
   ],
   "source": [
    "# Define the Graph Convolutional Network (GCN) model\n",
    "class GCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim):\n",
    "        super(GCN, self).__init__()\n",
    "        self.conv1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.conv2 = nn.Linear(hidden_dim, 1)  # Output dimension changed to 1 for binary classification\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x))\n",
    "        x = self.conv2(x)\n",
    "        return x\n",
    "\n",
    "# Initialize the GCN model\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "model = GCN(input_dim, hidden_dim)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Convert the data to PyTorch Geometric Data object\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, data.edge_index).squeeze()  # Squeeze the output to remove the singleton dimension\n",
    "    loss = criterion(output[data.edge_index[0]], data.edge_index[1].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08c4bd63",
   "metadata": {},
   "source": [
    "### New links prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a6b03180",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted link presence:\n",
      "tensor([[1],\n",
      "        [1],\n",
      "        [1]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# Function to predict new links using the trained model\n",
    "def predict_new_links(model, data, new_edges):\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(data.x, data.edge_index)\n",
    "        predicted_labels = output[new_edges[0]]\n",
    "        predicted_labels = (predicted_labels >= 0.8).int()  # Threshold predictions\n",
    "    return predicted_labels\n",
    "\n",
    "# Predict new links for a set of new edge indices\n",
    "new_edges = torch.tensor([[13, 17], [14, 17], [15, 17]], dtype=torch.long).t()  # Format: (start_nodes, end_nodes)\n",
    "predictions = predict_new_links(model, data, new_edges)\n",
    "\n",
    "# The predictions will be a tensor containing 0s and 1s, where 1 indicates - link and 0 indicates - no link.\n",
    "print(\"Predicted link presence:\")\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54e27b39",
   "metadata": {},
   "source": [
    "# Relational Graph Convolutional Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e32d63f5",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14256\\1303647172.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     27\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum_epochs\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     28\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 29\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     30\u001b[0m     \u001b[0mloss\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m     \u001b[0mloss\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14256\\1303647172.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv1\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconv2\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch\\nn\\modules\\module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[1;34m(self, *input, **kwargs)\u001b[0m\n\u001b[0;32m   1192\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[0;32m   1193\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[1;32m-> 1194\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0minput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1195\u001b[0m         \u001b[1;31m# Do not call functions when jit is used\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\Py_env\\lib\\site-packages\\torch_geometric\\nn\\conv\\rgcn_conv.py\u001b[0m in \u001b[0;36mforward\u001b[1;34m(self, x, edge_index, edge_type)\u001b[0m\n\u001b[0;32m    205\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    206\u001b[0m             \u001b[0medge_type\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0medge_index\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstorage\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 207\u001b[1;33m         \u001b[1;32massert\u001b[0m \u001b[0medge_type\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    208\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    209\u001b[0m         \u001b[1;31m# propagate_type: (x: Tensor, edge_type_ptr: OptTensor)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class RGCN(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, num_relations=1, num_bases=30):\n",
    "        super(RGCN, self).__init__()\n",
    "        self.conv1 = RGCNConv(input_dim, hidden_dim, num_relations, num_bases=num_bases)\n",
    "        self.conv2 = RGCNConv(hidden_dim, hidden_dim, num_relations, num_bases=num_bases)\n",
    "        self.out = nn.Linear(hidden_dim, 1)\n",
    "    \n",
    "    def forward(self, x, edge_index):\n",
    "        x = torch.relu(self.conv1(x, edge_index))\n",
    "        x = torch.relu(self.conv2(x, edge_index))\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "input_dim = node_features.shape[1]\n",
    "hidden_dim = 64\n",
    "model = RGCN(input_dim, hidden_dim)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "# Assuming you have the edge_index tensor\n",
    "edge_index = edge_index\n",
    "\n",
    "data = Data(x=node_features, edge_index=edge_index)\n",
    "\n",
    "num_epochs = 150\n",
    "for epoch in range(num_epochs + 1):\n",
    "    optimizer.zero_grad()\n",
    "    output = model(data.x, edge_index)\n",
    "    loss = criterion(output[edge_index[0]], edge_index[1].float())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    if epoch % 10 == 0:\n",
    "        print(f\"Epoch: {epoch}, Loss: {loss.item()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7797b10",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
